{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ID IMG                    COMPANY  \\\n",
      "0       1                        Walmart   \n",
      "1       2                    Exxon Mobil   \n",
      "2       3                        Chevron   \n",
      "3       4             Berkshire Hathaway   \n",
      "4       5                          Apple   \n",
      "..    ...  ..                        ...   \n",
      "963   996             Universal American   \n",
      "964   997                            AAR   \n",
      "965   998      Selective Insurance Group   \n",
      "966   999                        Gartner   \n",
      "967  1000              E*Trade Financial   \n",
      "\n",
      "                                     INDUSTRY                 WEBSITE  \\\n",
      "0                       General Merchandisers  corporate.walmart.com/   \n",
      "1                          Petroleum Refining          exxonmobil.com   \n",
      "2                          Petroleum Refining            chevron.com/   \n",
      "3    Insurance: Property and Casualty (Stock)   berkshirehathaway.com   \n",
      "4               Consumer Brands / Electronics   https://www.apple.com   \n",
      "..                                        ...                     ...   \n",
      "963   Health Care: Insurance and Managed Care   universalamerican.com   \n",
      "964                     Aerospace and Defense            aarcorp.com/   \n",
      "965  Insurance: Property and Casualty (Stock)          selective.com/   \n",
      "966           Information Technology Services            gartner.com/   \n",
      "967                                Securities  https://www.etrade.com   \n",
      "\n",
      "    NPS_SCORE                                     PROMOTER_SCORE  \n",
      "0          -4              Walmart Net Promoter Score Benchmarks  \n",
      "1           2          Exxon Mobil Net Promoter Score Benchmarks  \n",
      "2           5              Chevron Net Promoter Score Benchmarks  \n",
      "3          -6   Berkshire Hathaway Net Promoter Score Benchmarks  \n",
      "4          47                Apple Net Promoter Score Benchmarks  \n",
      "..        ...                                                ...  \n",
      "963        -7   Universal American Net Promoter Score Benchmarks  \n",
      "964        -7                  AAR Net Promoter Score Benchmarks  \n",
      "965        -6  Selective Insurance Group Net Promoter Score B...  \n",
      "966        -3              Gartner Net Promoter Score Benchmarks  \n",
      "967        -6    E*Trade Financial Net Promoter Score Benchmarks  \n",
      "\n",
      "[968 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "webhook_site_url = 'https://customer.guru/net-promoter-score/fortune-500'\n",
    "\n",
    "# Send a GET request to retrieve the data\n",
    "response = requests.get(webhook_site_url)\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "table = soup.find_all('table')\n",
    "rows = soup.find_all('tr')\n",
    "   \n",
    "data = []\n",
    "\n",
    "for row in rows:\n",
    "    cells = row.find_all('td')\n",
    "    row_data = [cell.text.strip() for cell in cells]\n",
    "    data.append(row_data)\n",
    "\n",
    "# Define column names\n",
    "column_names = ['ID', 'IMG', 'COMPANY', 'INDUSTRY', 'WEBSITE', 'NPS_SCORE', 'PROMOTER_SCORE']\n",
    "\n",
    "df = pd.DataFrame(data, columns=column_names)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established.\n"
     ]
    }
   ],
   "source": [
    "# import the pyodbc\n",
    "import pyodbc\n",
    "\n",
    "# Define the MSSQL connection string\n",
    "server_name = \"AGLJ-LAP-032\"\n",
    "database_name = \"master\"\n",
    "username = \"sqladmin\"\n",
    "password = \"Admin@12345\"\n",
    "# Set up the database connection\n",
    "con_string = (\n",
    "    f\"Driver={{SQL Server}};\"\n",
    "    f\"Server={server_name};\"\n",
    "    f\"Database={database_name};\"\n",
    "    f\"UID={username};\"\n",
    "    f\"PWD={password};\"\n",
    ")\n",
    "# connect the variable to the server\n",
    "conn = pyodbc.connect(con_string)\n",
    "\n",
    "if conn:\n",
    "    print(\"Connection established.\")\n",
    "else:\n",
    "    print(\"Connection failed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'Truuu' dropped.\n",
      "Table 'Truuu' created.\n"
     ]
    }
   ],
   "source": [
    "# Create the SQL table\n",
    "def create_table(conn):\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Check if the table exists\n",
    "    if cursor.tables(table='Truuu', tableType='TABLE').fetchone():\n",
    "        # If the table exists, drop it\n",
    "        drop_table_query = \"DROP TABLE Truuu\"\n",
    "        cursor.execute(drop_table_query)\n",
    "        print(\"Table 'Truuu' dropped.\")\n",
    "\n",
    "    # Create the table\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE Truuu  \n",
    "    (\n",
    "        ID INT NULL, \n",
    "        IMG VARCHAR(20) NULL, \n",
    "        COMPANY VARCHAR(200) NULL, \n",
    "        INDUSTRY VARCHAR(200) NULL, \n",
    "        WEBSITE VARCHAR(200) NULL,\n",
    "        NPS_SCORE INT NULL,\n",
    "        PROMOTER_SCORE VARCHAR(200) NULL\n",
    "    )\n",
    "    \"\"\"\n",
    "    cursor.execute(create_table_query)\n",
    "    print(\"Table 'Truuu' created.\")\n",
    "\n",
    "# Create a connection to the database\n",
    "conn = pyodbc.connect(con_string)\n",
    "\n",
    "# Call the create_table function\n",
    "create_table(conn)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into the SQL table\n",
    "cursor = conn.cursor()\n",
    "for _, row in df.iterrows():\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO Truuu (ID, IMG, COMPANY, INDUSTRY, WEBSITE, NPS_SCORE, PROMOTER_SCORE) \n",
    "    VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "    \"\"\"\n",
    "    values = tuple(row)\n",
    "    cursor.execute(insert_query, values)\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Company                       Industry  \\\n",
      "0     1         Apple  Consumer Brands / Electronics   \n",
      "1     2        Google     Consumer Brands / Internet   \n",
      "2     3     Microsoft          Technology / Software   \n",
      "3     4     Coca-Cola                      Beverages   \n",
      "4     5      Facebook     Consumer Brands / Internet   \n",
      "..  ... ..        ...                            ...   \n",
      "95   96       Philips  Consumer Brands / Electronics   \n",
      "96   97         Prada                         Luxury   \n",
      "97   98           RBC             Financial Services   \n",
      "98   99       Hershey         Food Consumer Products   \n",
      "99  100        Costco      Consumer Brands / Grocery   \n",
      "\n",
      "                       Website NPS Score  \\\n",
      "0        https://www.apple.com        47   \n",
      "1                   google.com        11   \n",
      "2   https://www.microsoft.com/        45   \n",
      "3                                      0   \n",
      "4    https://www.facebook.com/       -21   \n",
      "..                         ...       ...   \n",
      "95                                    33   \n",
      "96                   prada.com        -5   \n",
      "97                     rbc.com        -6   \n",
      "98        hersheyicecream.com/        -1   \n",
      "99                  costco.com        79   \n",
      "\n",
      "                                             \n",
      "0       Apple Net Promoter Score Benchmarks  \n",
      "1      Google Net Promoter Score Benchmarks  \n",
      "2   Microsoft Net Promoter Score Benchmarks  \n",
      "3   Coca-Cola Net Promoter Score Benchmarks  \n",
      "4    Facebook Net Promoter Score Benchmarks  \n",
      "..                                      ...  \n",
      "95    Philips Net Promoter Score Benchmarks  \n",
      "96      Prada Net Promoter Score Benchmarks  \n",
      "97        RBC Net Promoter Score Benchmarks  \n",
      "98    Hershey Net Promoter Score Benchmarks  \n",
      "99     Costco Net Promoter Score Benchmarks  \n",
      "\n",
      "[100 rows x 7 columns]\n",
      "Connection established.\n",
      "created good\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pyodbc\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"indexing past lexsort depth may impact performance\")\n",
    "\n",
    "webhook_site_url = 'https://customer.guru/net-promoter-score/top-brands'\n",
    "\n",
    "# Send a GET request to retrieve the data\n",
    "response = requests.get(webhook_site_url)\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "table = soup.find_all('table')\n",
    "rows = soup.find_all('tr')\n",
    "\n",
    "data = []\n",
    "\n",
    "for row in rows:\n",
    "    cells = row.find_all(['th', 'td'])\n",
    "    row_data = [cell.text.strip() for cell in cells]\n",
    "    data.append(row_data)\n",
    "\n",
    "table = soup.find_all('table')\n",
    "rows = soup.find_all('thead')\n",
    "\n",
    "col = []\n",
    "\n",
    "for row in rows:\n",
    "    cells = row.find_all('th')\n",
    "    row_data = [cell.text.strip() for cell in cells]\n",
    "    col.append(row_data)\n",
    "\n",
    "# Define column names\n",
    "# column_names = ['ID', 'IMG', 'COMPANY', 'INDUSTRY', 'WEBSITE', 'NPS_SCORE', 'PROMOTER_SCORE']\n",
    "\n",
    "df = pd.DataFrame(data, columns=col)\n",
    "print(df)\n",
    "\n",
    "# Define the MSSQL connection string\n",
    "server_name = \"AGLJ-LAP-032\"\n",
    "database_name = \"master\"\n",
    "username = \"sqladmin\"\n",
    "password = \"Admin@12345\"\n",
    "# Set up the database connection\n",
    "con_string = (\n",
    "    f\"Driver={{SQL Server}};\"\n",
    "    f\"Server={server_name};\"\n",
    "    f\"Database={database_name};\"\n",
    "    f\"UID={username};\"\n",
    "    f\"PWD={password};\"\n",
    ")\n",
    "# connect the variable to the server\n",
    "conn = pyodbc.connect(con_string)\n",
    "\n",
    "if conn:\n",
    "    print(\"Connection established.\")\n",
    "else:\n",
    "    print(\"Connection failed.\")\n",
    "\n",
    "# Create the SQL table\n",
    "table_name = 'Dataleak'\n",
    "\n",
    "create_table_query = f\"CREATE TABLE {table_name} (\"\n",
    "unique_columns = set()  # Set to store unique column names\n",
    "\n",
    "for column in df.columns:\n",
    "    # Modify the column name if it is already in the set of unique columns\n",
    "    modified_column = column\n",
    "    counter = 1\n",
    "    while modified_column in unique_columns:\n",
    "        modified_column = f\"{column}_{counter}\"\n",
    "        counter += 1\n",
    "    \n",
    "    unique_columns.add(modified_column)  # Add the modified column name to the set of unique columns\n",
    "    \n",
    "    column_datatype = \"VARCHAR(255)\"  # Set the data type to VARCHAR(255) for all columns\n",
    "    create_table_query += f\"[{modified_column}] {column_datatype}, \"\n",
    "\n",
    "# Remove the trailing comma and space\n",
    "create_table_query = create_table_query[:-2]\n",
    "create_table_query += \")\"\n",
    "\n",
    "# cursor.execute(create_table_query)\n",
    "\n",
    "if (create_table_query):\n",
    "    print('created good')\n",
    "else:\n",
    "    print('error')\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.16\n"
     ]
    }
   ],
   "source": [
    "import sqlalchemy\n",
    "\n",
    "\n",
    "print(sqlalchemy.__version__)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
